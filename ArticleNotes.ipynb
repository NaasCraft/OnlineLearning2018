{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Article notes\n",
    "\n",
    "[Multi-armed Bandit Models for the\n",
    "Optimal Design of Clinical Trials: Benefits\n",
    "and Challenges](https://arxiv.org/pdf/1507.08025.pdf),  \n",
    "_SofÃ­a S. Villar, Jack Bowden and James Wason, 2015_\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "- **Goal**: study algorithms for the **M**ulti **A**rmed **B**andit **P**roblem, using a Bayesian approach\n",
    "- Criteria:\n",
    "    - _exploration_ or _learning_: identify the best arm\n",
    "    - _exploitation_ or _earning_: maximize expected total reward\n",
    "\n",
    "\n",
    "## 2. Bayesian Bernouilli MABP\n",
    "\n",
    "- Each arm $k = 1, \\dots, K \\sim Bernouilli(p_k)$\n",
    "- Prior on $p_k \\sim Beta(s_{k,0}, f_{k,0})$\n",
    "- Posterior, having observed $S_{k,t} = s_{k,t}$ successes and $F_{k,t} = f_{k,t}$ failures: $$p_k^{(t)} \\sim Beta(s_{k,0} + s_{k,t}, \\, f_{k,0} + f_{k,t})$$\n",
    "\n",
    "Formulated as **Markov Control Process** (from the Optimal Control litterature):\n",
    "\n",
    "> - _state space_: $\\{(s_{k,0} + S_{k,t}, \\, f_{k,0} + F_{k,t}) \\in \\mathbb{N}^2_+ \\, | \\, S_{k,t} + F_{k,t} \\leq t \\quad \\forall t \\in 1 \\dots T\\}$\n",
    "\n",
    "> - _action space_: $\\{\\mathbf{a}_t = (a_{k,t})_k \\, | \\, a_{k,t} = \\mathbb{1}_{\\text{arm} \\, k \\, \\text{used at} \\, t}\\}$  \n",
    "    > Note: at each $t$, $\\sum_k a_{k, t} = 1$\n",
    "\n",
    "> - _transition law_: if arm $k$ is drawn, \n",
    "    $$\\mathbb{P}(S_{k, t+1} = s_{k, t} + 1) = \\frac{s_{k,0} + s_{k,t}}{s_{k,0} + s_{k,t} + f_{k,0} + f_{k,t}}$$\n",
    "    $$\\mathbb{P}(F_{k, t+1} = f_{k, t} + 1) = \\frac{f_{k,0} + f_{k,t}}{s_{k,0} + s_{k,t} + f_{k,0} + f_{k,t}}$$\n",
    "\n",
    "Objective: construct an optimal _policy_ (i.e. a set of actions $\\{\\mathbf{a}_t\\}_t$), according to the objective function\n",
    "    $$\\mathbb{E}^\\pi \\Big[ \\sum_{t=0}^{T-1} \\sum_{k=1}^K d^t \\frac{s_{k,0} + S_{k,t}}{s_{k,0} + S_{k,t} + f_{k,0} + F_{k,t}} \\cdot a_{k,t} \\quad | \\quad (x_{k,0}) \\Big]$$\n",
    "    \n",
    "where we know $\\mathbb{E}^\\pi \\bigg[\\frac{s_{k,0} + S_{k,t}}{s_{k,0} + S_{k,t} + f_{k,0} + F_{k,t}}\\bigg]$ is the expected reward at timestep $t$ for drawing arm $k$\n",
    "\n",
    "To ease notations, let us define $\\lambda_{k,t} = \\frac{s_{k,0} + s_{k,t}}{s_{k,0} + s_{k,t} + f_{k,0} + f_{k,t}}$ and $\\Lambda_{k,t} = \\frac{s_{k,0} + S_{k,t}}{s_{k,0} + S_{k,t} + f_{k,0} + F_{k,t}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Matrix notation_ ($\\Lambda$ and $\\mathbf{a}$ are of size (K x T), $\\gamma$ T-vector): $$\\Lambda = (\\Lambda_{k,t})_{(k,t) \\in [[1, K]] \\times [[0, T-1]]} \\quad \\mathbf{a} = (\\mathbf{a}_t)_{t \\in [[0, T-1]]} \\quad \\gamma = (d^t)_{t \\in [[0, T-1]]}$$\n",
    "\n",
    "Then, the \"Total Discounted Expected Reward\" is : $\\mathbb{E}^\\pi \\big(\\gamma' \\Lambda' \\mathbf{a} \\, | \\, \\mathbf{x} \\big)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduces the _regret_: $$\\rho = T\\max_k p_k - \\mathbb{E}^\\pi \\big(\\mathbf{1}_T Y' \\mathbf{a} \\big)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Infinite-horizon case\n",
    "\n",
    "__Bellman optimality equation__:\n",
    "\n",
    "if we note the optimal value at date $T$: $v^*_T = \\max_\\pi \\mathbb{E}^\\pi \\big(\\gamma' \\Lambda' \\mathbf{a} \\, | \\, \\mathbf{x} \\big)$, then we have: $$v^*_T = \\max_k \\big( \\lambda_{k,t} + d \\, \\mathbb{E}^\\pi ( v^*_{T + 1} ) \\big)$$\n",
    "\n",
    "__Gittins index__:\n",
    "\n",
    "$$\\mathcal{G}_k(x_{k,t}) = \\sup_{\\tau \\geq 1} \\mathbb{E}^\\pi \\Big( \\frac{\\sum_{i=0}^{\\tau - 1} \\mathcal{R}(X_{k, t+i}, 1) \\, d^i}{\\sum_{i=0}^{\\tau - 1} \\mathcal{C}(X_{k, t+i}, 1) d^i} \\quad | \\; x_{k,t} \\Big)$$\n",
    "\n",
    "...or in our case:\n",
    "\n",
    "$$\\mathcal{G}_k(x_{k,t}) = \\sup_{\\tau \\geq 1} \\mathbb{E}^\\pi \\Big( \\frac{\\sum_{i=0}^{\\tau - 1} \\Lambda_{k, t+i} \\, d^i}{\\sum_{i=0}^{\\tau - 1} d^i} \\quad | \\; x_{k,t} \\Big)$$\n",
    "\n",
    "_Efficient computation method_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
